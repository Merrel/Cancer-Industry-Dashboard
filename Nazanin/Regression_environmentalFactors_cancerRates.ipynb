{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Setting rando seed to get reproducible runs\n",
    "RSEED = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>county</th>\n",
       "      <th>payann</th>\n",
       "      <th>estab</th>\n",
       "      <th>emp</th>\n",
       "      <th>ACID</th>\n",
       "      <th>ENRG</th>\n",
       "      <th>ETOX</th>\n",
       "      <th>EUTR</th>\n",
       "      <th>FOOD</th>\n",
       "      <th>...</th>\n",
       "      <th>MINE</th>\n",
       "      <th>MSW</th>\n",
       "      <th>NREN</th>\n",
       "      <th>OZON</th>\n",
       "      <th>PEST</th>\n",
       "      <th>REN</th>\n",
       "      <th>SMOG</th>\n",
       "      <th>VADD</th>\n",
       "      <th>WATR</th>\n",
       "      <th>annual_count_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22002344</td>\n",
       "      <td>91</td>\n",
       "      <td>128668</td>\n",
       "      <td>594</td>\n",
       "      <td>4954</td>\n",
       "      <td>299.152569</td>\n",
       "      <td>7.286445e+05</td>\n",
       "      <td>1963.026340</td>\n",
       "      <td>26.933851</td>\n",
       "      <td>709.634497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2149.369209</td>\n",
       "      <td>4.351692e+05</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>3.497395e-02</td>\n",
       "      <td>293475.377416</td>\n",
       "      <td>2949.632736</td>\n",
       "      <td>79914.159702</td>\n",
       "      <td>7851.498268</td>\n",
       "      <td>2179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41609466</td>\n",
       "      <td>516</td>\n",
       "      <td>953498</td>\n",
       "      <td>3340</td>\n",
       "      <td>32629</td>\n",
       "      <td>133.420049</td>\n",
       "      <td>6.931874e+03</td>\n",
       "      <td>3765.662479</td>\n",
       "      <td>132.635472</td>\n",
       "      <td>4843.498718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.674254e+04</td>\n",
       "      <td>16148.087370</td>\n",
       "      <td>4.932628e+03</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>8.577729e-02</td>\n",
       "      <td>1999.246044</td>\n",
       "      <td>4438.579174</td>\n",
       "      <td>576096.081165</td>\n",
       "      <td>1633.902304</td>\n",
       "      <td>8579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19847485</td>\n",
       "      <td>410</td>\n",
       "      <td>53138</td>\n",
       "      <td>361</td>\n",
       "      <td>1715</td>\n",
       "      <td>102.817249</td>\n",
       "      <td>6.064801e+00</td>\n",
       "      <td>3298.083216</td>\n",
       "      <td>13.598555</td>\n",
       "      <td>126.810329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>554.606997</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>4.371549e-02</td>\n",
       "      <td>6.064801</td>\n",
       "      <td>3649.913530</td>\n",
       "      <td>29611.275038</td>\n",
       "      <td>511.844967</td>\n",
       "      <td>1052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16221839</td>\n",
       "      <td>469</td>\n",
       "      <td>20778</td>\n",
       "      <td>205</td>\n",
       "      <td>655</td>\n",
       "      <td>30.042694</td>\n",
       "      <td>2.012683e+04</td>\n",
       "      <td>1807.410043</td>\n",
       "      <td>4.819015</td>\n",
       "      <td>76.420984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>309.053357</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>2.437340e-02</td>\n",
       "      <td>20126.828138</td>\n",
       "      <td>1064.780004</td>\n",
       "      <td>10666.884789</td>\n",
       "      <td>285.555832</td>\n",
       "      <td>961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23008810</td>\n",
       "      <td>855</td>\n",
       "      <td>61132</td>\n",
       "      <td>455</td>\n",
       "      <td>2161</td>\n",
       "      <td>32.192658</td>\n",
       "      <td>1.131970e+01</td>\n",
       "      <td>416.998063</td>\n",
       "      <td>4.320160</td>\n",
       "      <td>232.490017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>896.650774</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>6.501047e-03</td>\n",
       "      <td>11.319704</td>\n",
       "      <td>1165.911030</td>\n",
       "      <td>36511.029249</td>\n",
       "      <td>98.727235</td>\n",
       "      <td>2327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>6352509</td>\n",
       "      <td>3774</td>\n",
       "      <td>491651</td>\n",
       "      <td>989</td>\n",
       "      <td>9029</td>\n",
       "      <td>587.935749</td>\n",
       "      <td>3.629382e+06</td>\n",
       "      <td>813.473206</td>\n",
       "      <td>105.117742</td>\n",
       "      <td>1001.624899</td>\n",
       "      <td>...</td>\n",
       "      <td>1.394053e+06</td>\n",
       "      <td>4115.339612</td>\n",
       "      <td>3.628234e+06</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>8.917167e-03</td>\n",
       "      <td>1147.804947</td>\n",
       "      <td>19410.599796</td>\n",
       "      <td>312217.341832</td>\n",
       "      <td>5945.474594</td>\n",
       "      <td>1231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>7237066</td>\n",
       "      <td>4524</td>\n",
       "      <td>361056</td>\n",
       "      <td>1402</td>\n",
       "      <td>8689</td>\n",
       "      <td>37.178584</td>\n",
       "      <td>9.249760e+02</td>\n",
       "      <td>7592.166446</td>\n",
       "      <td>25.091516</td>\n",
       "      <td>2044.202199</td>\n",
       "      <td>...</td>\n",
       "      <td>8.200278e+00</td>\n",
       "      <td>6423.591808</td>\n",
       "      <td>4.857347e+02</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>2.019774e-01</td>\n",
       "      <td>439.241290</td>\n",
       "      <td>1412.961358</td>\n",
       "      <td>210925.667302</td>\n",
       "      <td>1777.330068</td>\n",
       "      <td>773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>5811849</td>\n",
       "      <td>3813</td>\n",
       "      <td>145379</td>\n",
       "      <td>442</td>\n",
       "      <td>3287</td>\n",
       "      <td>96.737078</td>\n",
       "      <td>1.919977e+06</td>\n",
       "      <td>112.140420</td>\n",
       "      <td>13.936063</td>\n",
       "      <td>384.841414</td>\n",
       "      <td>...</td>\n",
       "      <td>3.997271e+05</td>\n",
       "      <td>1420.508279</td>\n",
       "      <td>1.919961e+06</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>4.621011e-04</td>\n",
       "      <td>16.608615</td>\n",
       "      <td>3486.862556</td>\n",
       "      <td>97322.166731</td>\n",
       "      <td>582.400056</td>\n",
       "      <td>635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>4442825</td>\n",
       "      <td>3053</td>\n",
       "      <td>31951</td>\n",
       "      <td>283</td>\n",
       "      <td>907</td>\n",
       "      <td>31.417667</td>\n",
       "      <td>2.756565e+05</td>\n",
       "      <td>28.072519</td>\n",
       "      <td>4.183471</td>\n",
       "      <td>101.472042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>518.501787</td>\n",
       "      <td>2.756546e+05</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3.860924e-07</td>\n",
       "      <td>1.845259</td>\n",
       "      <td>1176.237930</td>\n",
       "      <td>20257.950393</td>\n",
       "      <td>20.344697</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>3570423</td>\n",
       "      <td>2565</td>\n",
       "      <td>19638</td>\n",
       "      <td>167</td>\n",
       "      <td>496</td>\n",
       "      <td>34.618906</td>\n",
       "      <td>4.287379e+05</td>\n",
       "      <td>68.249727</td>\n",
       "      <td>4.688287</td>\n",
       "      <td>96.308035</td>\n",
       "      <td>...</td>\n",
       "      <td>1.711363e+04</td>\n",
       "      <td>348.003649</td>\n",
       "      <td>4.286608e+05</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>9.432837e-04</td>\n",
       "      <td>77.061234</td>\n",
       "      <td>1321.995548</td>\n",
       "      <td>12995.136488</td>\n",
       "      <td>47.904143</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3133 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  county  payann  estab    emp        ACID          ENRG  \\\n",
       "0       22002344      91  128668    594   4954  299.152569  7.286445e+05   \n",
       "1       41609466     516  953498   3340  32629  133.420049  6.931874e+03   \n",
       "2       19847485     410   53138    361   1715  102.817249  6.064801e+00   \n",
       "3       16221839     469   20778    205    655   30.042694  2.012683e+04   \n",
       "4       23008810     855   61132    455   2161   32.192658  1.131970e+01   \n",
       "...          ...     ...     ...    ...    ...         ...           ...   \n",
       "3128     6352509    3774  491651    989   9029  587.935749  3.629382e+06   \n",
       "3129     7237066    4524  361056   1402   8689   37.178584  9.249760e+02   \n",
       "3130     5811849    3813  145379    442   3287   96.737078  1.919977e+06   \n",
       "3131     4442825    3053   31951    283    907   31.417667  2.756565e+05   \n",
       "3132     3570423    2565   19638    167    496   34.618906  4.287379e+05   \n",
       "\n",
       "             ETOX        EUTR         FOOD  ...          MINE           MSW  \\\n",
       "0     1963.026340   26.933851   709.634497  ...  0.000000e+00   2149.369209   \n",
       "1     3765.662479  132.635472  4843.498718  ...  1.674254e+04  16148.087370   \n",
       "2     3298.083216   13.598555   126.810329  ...  0.000000e+00    554.606997   \n",
       "3     1807.410043    4.819015    76.420984  ...  0.000000e+00    309.053357   \n",
       "4      416.998063    4.320160   232.490017  ...  0.000000e+00    896.650774   \n",
       "...           ...         ...          ...  ...           ...           ...   \n",
       "3128   813.473206  105.117742  1001.624899  ...  1.394053e+06   4115.339612   \n",
       "3129  7592.166446   25.091516  2044.202199  ...  8.200278e+00   6423.591808   \n",
       "3130   112.140420   13.936063   384.841414  ...  3.997271e+05   1420.508279   \n",
       "3131    28.072519    4.183471   101.472042  ...  0.000000e+00    518.501787   \n",
       "3132    68.249727    4.688287    96.308035  ...  1.711363e+04    348.003649   \n",
       "\n",
       "              NREN      OZON          PEST            REN          SMOG  \\\n",
       "0     4.351692e+05  0.002923  3.497395e-02  293475.377416   2949.632736   \n",
       "1     4.932628e+03  0.007422  8.577729e-02    1999.246044   4438.579174   \n",
       "2     0.000000e+00  0.000153  4.371549e-02       6.064801   3649.913530   \n",
       "3     0.000000e+00  0.000593  2.437340e-02   20126.828138   1064.780004   \n",
       "4     0.000000e+00  0.002463  6.501047e-03      11.319704   1165.911030   \n",
       "...            ...       ...           ...            ...           ...   \n",
       "3128  3.628234e+06  0.003711  8.917167e-03    1147.804947  19410.599796   \n",
       "3129  4.857347e+02  0.003347  2.019774e-01     439.241290   1412.961358   \n",
       "3130  1.919961e+06  0.000773  4.621011e-04      16.608615   3486.862556   \n",
       "3131  2.756546e+05  0.000140  3.860924e-07       1.845259   1176.237930   \n",
       "3132  4.286608e+05  0.000395  9.432837e-04      77.061234   1321.995548   \n",
       "\n",
       "               VADD         WATR  annual_count_avg  \n",
       "0      79914.159702  7851.498268            2179.0  \n",
       "1     576096.081165  1633.902304            8579.0  \n",
       "2      29611.275038   511.844967            1052.0  \n",
       "3      10666.884789   285.555832             961.0  \n",
       "4      36511.029249    98.727235            2327.0  \n",
       "...             ...          ...               ...  \n",
       "3128  312217.341832  5945.474594            1231.0  \n",
       "3129  210925.667302  1777.330068             773.0  \n",
       "3130   97322.166731   582.400056             635.0  \n",
       "3131   20257.950393    20.344697             411.0  \n",
       "3132   12995.136488    47.904143             386.0  \n",
       "\n",
       "[3133 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"merged_indicatorsVSCancer.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACID</th>\n",
       "      <th>ENRG</th>\n",
       "      <th>ETOX</th>\n",
       "      <th>EUTR</th>\n",
       "      <th>FOOD</th>\n",
       "      <th>GCC</th>\n",
       "      <th>HAPS</th>\n",
       "      <th>HAZW</th>\n",
       "      <th>HC</th>\n",
       "      <th>HNC</th>\n",
       "      <th>...</th>\n",
       "      <th>MINE</th>\n",
       "      <th>MSW</th>\n",
       "      <th>NREN</th>\n",
       "      <th>OZON</th>\n",
       "      <th>PEST</th>\n",
       "      <th>REN</th>\n",
       "      <th>SMOG</th>\n",
       "      <th>VADD</th>\n",
       "      <th>WATR</th>\n",
       "      <th>annual_count_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.152569</td>\n",
       "      <td>7.286445e+05</td>\n",
       "      <td>1963.026340</td>\n",
       "      <td>26.933851</td>\n",
       "      <td>709.634497</td>\n",
       "      <td>106259.392004</td>\n",
       "      <td>10.732168</td>\n",
       "      <td>15.515155</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2149.369209</td>\n",
       "      <td>4.351692e+05</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>3.497395e-02</td>\n",
       "      <td>293475.377416</td>\n",
       "      <td>2949.632736</td>\n",
       "      <td>79914.159702</td>\n",
       "      <td>7851.498268</td>\n",
       "      <td>2179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133.420049</td>\n",
       "      <td>6.931874e+03</td>\n",
       "      <td>3765.662479</td>\n",
       "      <td>132.635472</td>\n",
       "      <td>4843.498718</td>\n",
       "      <td>43881.445254</td>\n",
       "      <td>31.163349</td>\n",
       "      <td>614.863426</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.674254e+04</td>\n",
       "      <td>16148.087370</td>\n",
       "      <td>4.932628e+03</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>8.577729e-02</td>\n",
       "      <td>1999.246044</td>\n",
       "      <td>4438.579174</td>\n",
       "      <td>576096.081165</td>\n",
       "      <td>1633.902304</td>\n",
       "      <td>8579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.817249</td>\n",
       "      <td>6.064801e+00</td>\n",
       "      <td>3298.083216</td>\n",
       "      <td>13.598555</td>\n",
       "      <td>126.810329</td>\n",
       "      <td>19913.180328</td>\n",
       "      <td>7.238123</td>\n",
       "      <td>3.329358</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>554.606997</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>4.371549e-02</td>\n",
       "      <td>6.064801</td>\n",
       "      <td>3649.913530</td>\n",
       "      <td>29611.275038</td>\n",
       "      <td>511.844967</td>\n",
       "      <td>1052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.042694</td>\n",
       "      <td>2.012683e+04</td>\n",
       "      <td>1807.410043</td>\n",
       "      <td>4.819015</td>\n",
       "      <td>76.420984</td>\n",
       "      <td>5751.086704</td>\n",
       "      <td>2.622439</td>\n",
       "      <td>4.793377</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>309.053357</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>2.437340e-02</td>\n",
       "      <td>20126.828138</td>\n",
       "      <td>1064.780004</td>\n",
       "      <td>10666.884789</td>\n",
       "      <td>285.555832</td>\n",
       "      <td>961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.192658</td>\n",
       "      <td>1.131970e+01</td>\n",
       "      <td>416.998063</td>\n",
       "      <td>4.320160</td>\n",
       "      <td>232.490017</td>\n",
       "      <td>6564.143301</td>\n",
       "      <td>3.770756</td>\n",
       "      <td>9.737300</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>896.650774</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>6.501047e-03</td>\n",
       "      <td>11.319704</td>\n",
       "      <td>1165.911030</td>\n",
       "      <td>36511.029249</td>\n",
       "      <td>98.727235</td>\n",
       "      <td>2327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>587.935749</td>\n",
       "      <td>3.629382e+06</td>\n",
       "      <td>813.473206</td>\n",
       "      <td>105.117742</td>\n",
       "      <td>1001.624899</td>\n",
       "      <td>205214.901809</td>\n",
       "      <td>46.136744</td>\n",
       "      <td>40.714622</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.394053e+06</td>\n",
       "      <td>4115.339612</td>\n",
       "      <td>3.628234e+06</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>8.917167e-03</td>\n",
       "      <td>1147.804947</td>\n",
       "      <td>19410.599796</td>\n",
       "      <td>312217.341832</td>\n",
       "      <td>5945.474594</td>\n",
       "      <td>1231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>37.178584</td>\n",
       "      <td>9.249760e+02</td>\n",
       "      <td>7592.166446</td>\n",
       "      <td>25.091516</td>\n",
       "      <td>2044.202199</td>\n",
       "      <td>14614.797183</td>\n",
       "      <td>39.699930</td>\n",
       "      <td>167.219233</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>...</td>\n",
       "      <td>8.200278e+00</td>\n",
       "      <td>6423.591808</td>\n",
       "      <td>4.857347e+02</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>2.019774e-01</td>\n",
       "      <td>439.241290</td>\n",
       "      <td>1412.961358</td>\n",
       "      <td>210925.667302</td>\n",
       "      <td>1777.330068</td>\n",
       "      <td>773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>96.737078</td>\n",
       "      <td>1.919977e+06</td>\n",
       "      <td>112.140420</td>\n",
       "      <td>13.936063</td>\n",
       "      <td>384.841414</td>\n",
       "      <td>32123.362015</td>\n",
       "      <td>10.644368</td>\n",
       "      <td>8.324102</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>...</td>\n",
       "      <td>3.997271e+05</td>\n",
       "      <td>1420.508279</td>\n",
       "      <td>1.919961e+06</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>4.621011e-04</td>\n",
       "      <td>16.608615</td>\n",
       "      <td>3486.862556</td>\n",
       "      <td>97322.166731</td>\n",
       "      <td>582.400056</td>\n",
       "      <td>635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>31.417667</td>\n",
       "      <td>2.756565e+05</td>\n",
       "      <td>28.072519</td>\n",
       "      <td>4.183471</td>\n",
       "      <td>101.472042</td>\n",
       "      <td>6346.644246</td>\n",
       "      <td>2.766800</td>\n",
       "      <td>2.369265</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>518.501787</td>\n",
       "      <td>2.756546e+05</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3.860924e-07</td>\n",
       "      <td>1.845259</td>\n",
       "      <td>1176.237930</td>\n",
       "      <td>20257.950393</td>\n",
       "      <td>20.344697</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>34.618906</td>\n",
       "      <td>4.287379e+05</td>\n",
       "      <td>68.249727</td>\n",
       "      <td>4.688287</td>\n",
       "      <td>96.308035</td>\n",
       "      <td>8445.776762</td>\n",
       "      <td>3.359196</td>\n",
       "      <td>1.517319</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.711363e+04</td>\n",
       "      <td>348.003649</td>\n",
       "      <td>4.286608e+05</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>9.432837e-04</td>\n",
       "      <td>77.061234</td>\n",
       "      <td>1321.995548</td>\n",
       "      <td>12995.136488</td>\n",
       "      <td>47.904143</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3133 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ACID          ENRG         ETOX        EUTR         FOOD  \\\n",
       "0     299.152569  7.286445e+05  1963.026340   26.933851   709.634497   \n",
       "1     133.420049  6.931874e+03  3765.662479  132.635472  4843.498718   \n",
       "2     102.817249  6.064801e+00  3298.083216   13.598555   126.810329   \n",
       "3      30.042694  2.012683e+04  1807.410043    4.819015    76.420984   \n",
       "4      32.192658  1.131970e+01   416.998063    4.320160   232.490017   \n",
       "...          ...           ...          ...         ...          ...   \n",
       "3128  587.935749  3.629382e+06   813.473206  105.117742  1001.624899   \n",
       "3129   37.178584  9.249760e+02  7592.166446   25.091516  2044.202199   \n",
       "3130   96.737078  1.919977e+06   112.140420   13.936063   384.841414   \n",
       "3131   31.417667  2.756565e+05    28.072519    4.183471   101.472042   \n",
       "3132   34.618906  4.287379e+05    68.249727    4.688287    96.308035   \n",
       "\n",
       "                GCC       HAPS        HAZW        HC       HNC  ...  \\\n",
       "0     106259.392004  10.732168   15.515155  0.000006  0.000024  ...   \n",
       "1      43881.445254  31.163349  614.863426  0.000025  0.000110  ...   \n",
       "2      19913.180328   7.238123    3.329358  0.000016  0.000062  ...   \n",
       "3       5751.086704   2.622439    4.793377  0.000005  0.000030  ...   \n",
       "4       6564.143301   3.770756    9.737300  0.000005  0.000021  ...   \n",
       "...             ...        ...         ...       ...       ...  ...   \n",
       "3128  205214.901809  46.136744   40.714622  0.000113  0.000664  ...   \n",
       "3129   14614.797183  39.699930  167.219233  0.000015  0.000061  ...   \n",
       "3130   32123.362015  10.644368    8.324102  0.000019  0.000117  ...   \n",
       "3131    6346.644246   2.766800    2.369265  0.000005  0.000024  ...   \n",
       "3132    8445.776762   3.359196    1.517319  0.000008  0.000049  ...   \n",
       "\n",
       "              MINE           MSW          NREN      OZON          PEST  \\\n",
       "0     0.000000e+00   2149.369209  4.351692e+05  0.002923  3.497395e-02   \n",
       "1     1.674254e+04  16148.087370  4.932628e+03  0.007422  8.577729e-02   \n",
       "2     0.000000e+00    554.606997  0.000000e+00  0.000153  4.371549e-02   \n",
       "3     0.000000e+00    309.053357  0.000000e+00  0.000593  2.437340e-02   \n",
       "4     0.000000e+00    896.650774  0.000000e+00  0.002463  6.501047e-03   \n",
       "...            ...           ...           ...       ...           ...   \n",
       "3128  1.394053e+06   4115.339612  3.628234e+06  0.003711  8.917167e-03   \n",
       "3129  8.200278e+00   6423.591808  4.857347e+02  0.003347  2.019774e-01   \n",
       "3130  3.997271e+05   1420.508279  1.919961e+06  0.000773  4.621011e-04   \n",
       "3131  0.000000e+00    518.501787  2.756546e+05  0.000140  3.860924e-07   \n",
       "3132  1.711363e+04    348.003649  4.286608e+05  0.000395  9.432837e-04   \n",
       "\n",
       "                REN          SMOG           VADD         WATR  \\\n",
       "0     293475.377416   2949.632736   79914.159702  7851.498268   \n",
       "1       1999.246044   4438.579174  576096.081165  1633.902304   \n",
       "2          6.064801   3649.913530   29611.275038   511.844967   \n",
       "3      20126.828138   1064.780004   10666.884789   285.555832   \n",
       "4         11.319704   1165.911030   36511.029249    98.727235   \n",
       "...             ...           ...            ...          ...   \n",
       "3128    1147.804947  19410.599796  312217.341832  5945.474594   \n",
       "3129     439.241290   1412.961358  210925.667302  1777.330068   \n",
       "3130      16.608615   3486.862556   97322.166731   582.400056   \n",
       "3131       1.845259   1176.237930   20257.950393    20.344697   \n",
       "3132      77.061234   1321.995548   12995.136488    47.904143   \n",
       "\n",
       "      annual_count_avg  \n",
       "0               2179.0  \n",
       "1               8579.0  \n",
       "2               1052.0  \n",
       "3                961.0  \n",
       "4               2327.0  \n",
       "...                ...  \n",
       "3128            1231.0  \n",
       "3129             773.0  \n",
       "3130             635.0  \n",
       "3131             411.0  \n",
       "3132             386.0  \n",
       "\n",
       "[3133 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df[['ACID', 'ENRG',\n",
    "       'ETOX', 'EUTR', 'FOOD', 'GCC', 'HAPS', 'HAZW', 'HC', 'HNC', 'HRSP',\n",
    "       'HTOX', 'JOBS', 'LAND', 'METL', 'MINE', 'MSW', 'NREN', 'OZON', 'PEST',\n",
    "       'REN', 'SMOG', 'VADD', 'WATR', 'annual_count_avg']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor for environmental factors in a county and cancer rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain (2193, 24)\n",
      "XTest (940, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1=data.loc[:, :'WATR']\n",
    "y = data['annual_count_avg']\n",
    "\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(x1, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = RSEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "X_train = scaler.transform(X_train1)\n",
    "X_test = scaler.transform(X_test1)\n",
    "\n",
    "print(\"XTrain\",X_train.shape)\n",
    "print(\"XTest\",X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=100, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the model with 10 trees\n",
    "regressor = RandomForestRegressor(n_estimators = 100,\n",
    "                                  random_state = RSEED)\n",
    "\n",
    "# Fit on training data\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for train:\n",
      "\n",
      "Accuracy Train -inf%\n",
      "r2_score Train: 0.9603257019945082\n",
      "\n",
      "\n",
      "Evaluation for test:\n",
      "\n",
      "Accuracy Test -inf%\n",
      "r2_score Test: 0.8700949707169692\n",
      "score 0.8700949707169692\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "train_rf_predictions = regressor.predict(X_train)\n",
    "rf_predictions = regressor.predict(X_test)\n",
    "MAE_train = metrics.mean_absolute_error(y_train, train_rf_predictions)\n",
    "RMSE_train = np.sqrt(metrics.mean_squared_error(y_train, train_rf_predictions))\n",
    "MAPE_train = 100 * np.mean(abs(train_rf_predictions - y_train)/abs(y_train))\n",
    "accuracy_train = 100 - MAPE_train\n",
    "r2_train = metrics.r2_score(y_train, train_rf_predictions)\n",
    "\n",
    "MAE_test = metrics.mean_absolute_error(y_test, rf_predictions)\n",
    "RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, rf_predictions))\n",
    "MAPE_test = 100 * np.mean(abs(rf_predictions - y_test)/abs(y_test))\n",
    "accuracy_test = 100 - MAPE_test\n",
    "r2_test = metrics.r2_score(y_test, rf_predictions)\n",
    "print(\"Evaluation for train:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Train:', MAE_train)    \n",
    "#print('Root Mean Squared Error Train:', RMSE_train)\n",
    "#print('Mean Absolute Percentage Error Train:', MAPE_train)\n",
    "print('Accuracy Train', str(accuracy_train) + \"%\")\n",
    "print('r2_score Train:',r2_train)\n",
    "print()\n",
    "print()\n",
    "print(\"Evaluation for test:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Test:', MAE_test)    \n",
    "#print('Root Mean Squared Error Test:', RMSE_test)\n",
    "#print('Mean Absolute Percentage Error Test:', MAPE_test)\n",
    "print('Accuracy Test', str(accuracy_test) + \"%\")\n",
    "print('r2_score Test:', r2_test)\n",
    "print(\"score\",regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.argsort(regressor.feature_importances_)[::-1]\n",
    "imp = regressor.feature_importances_[ind][:24]\n",
    "cols =x1.columns[ind][:24]\n",
    "pl = pd.Series(imp, index=cols).plot(kind='barh', title='Random Forest Feature Importance')\n",
    "pl.set_xlabel(\"Coefficient Strength\")\n",
    "pl.set_ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor for HTOX,HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain (2193, 2)\n",
      "XTest (940, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1=data[['HTOX','HC']]\n",
    "\n",
    "y = data['annual_count_avg']\n",
    "\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(x1, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = RSEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "X_train = scaler.transform(X_train1)\n",
    "X_test = scaler.transform(X_test1)\n",
    "\n",
    "print(\"XTrain\",X_train.shape)\n",
    "print(\"XTest\",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=100, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the model with 10 trees\n",
    "regressor2 = RandomForestRegressor(n_estimators = 100,\n",
    "                                  random_state = RSEED)\n",
    "\n",
    "# Fit on training data\n",
    "regressor2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for train:\n",
      "\n",
      "Accuracy Train -inf%\n",
      "r2_score Train: 0.9406317407812158\n",
      "\n",
      "\n",
      "Evaluation for test:\n",
      "\n",
      "Accuracy Test -inf%\n",
      "r2_score Test: 0.41378470045227933\n",
      "score 0.41378470045227933\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "train_rf_predictions = regressor2.predict(X_train)\n",
    "rf_predictions = regressor2.predict(X_test)\n",
    "MAE_train = metrics.mean_absolute_error(y_train, train_rf_predictions)\n",
    "RMSE_train = np.sqrt(metrics.mean_squared_error(y_train, train_rf_predictions))\n",
    "MAPE_train = 100 * np.mean(abs(train_rf_predictions - y_train)/abs(y_train))\n",
    "accuracy_train = 100 - MAPE_train\n",
    "r2_train = metrics.r2_score(y_train, train_rf_predictions)\n",
    "\n",
    "MAE_test = metrics.mean_absolute_error(y_test, rf_predictions)\n",
    "RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, rf_predictions))\n",
    "MAPE_test = 100 * np.mean(abs(rf_predictions - y_test)/abs(y_test))\n",
    "accuracy_test = 100 - MAPE_test\n",
    "r2_test = metrics.r2_score(y_test, rf_predictions)\n",
    "print(\"Evaluation for train:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Train:', MAE_train)    \n",
    "#print('Root Mean Squared Error Train:', RMSE_train)\n",
    "#print('Mean Absolute Percentage Error Train:', MAPE_train)\n",
    "print('Accuracy Train', str(accuracy_train) + \"%\")\n",
    "print('r2_score Train:',r2_train)\n",
    "print()\n",
    "print()\n",
    "print(\"Evaluation for test:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Test:', MAE_test)    \n",
    "#print('Root Mean Squared Error Test:', RMSE_test)\n",
    "#print('Mean Absolute Percentage Error Test:', MAPE_test)\n",
    "print('Accuracy Test', str(accuracy_test) + \"%\")\n",
    "print('r2_score Test:', r2_test)\n",
    "print(\"score\",regressor2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.argsort(regressor2.feature_importances_)[::-1]\n",
    "imp = regressor2.feature_importances_[ind][:2]\n",
    "cols =x1.columns[ind][:2]\n",
    "#print(imp)\n",
    "pl = pd.Series(imp, index=cols).plot(kind='barh', title='Random Forest Feature Importance')\n",
    "pl.set_xlabel(\"Coefficient Strength\")\n",
    "pl.set_ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for environmental factors in a county and cancer rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain (2193, 24)\n",
      "XTest (940, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1=data.loc[:, :'WATR']\n",
    "y = data['annual_count_avg']\n",
    "\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(x1, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = RSEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "X_train = scaler.transform(X_train1)\n",
    "X_test = scaler.transform(X_test1)\n",
    "\n",
    "print(\"XTrain\",X_train.shape)\n",
    "print(\"XTest\",X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model \n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit on training data\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for train:\n",
      "\n",
      "Accuracy Train -inf%\n",
      "r2_score Train: 0.8585743357921237\n",
      "\n",
      "\n",
      "Evaluation for test:\n",
      "\n",
      "Accuracy Test -inf%\n",
      "r2_score Test: 0.4621527729275319\n",
      "score 0.06170212765957447\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "train_rf_predictions = lr.predict(X_train)\n",
    "rf_predictions = lr.predict(X_test)\n",
    "MAE_train = metrics.mean_absolute_error(y_train, train_rf_predictions)\n",
    "RMSE_train = np.sqrt(metrics.mean_squared_error(y_train, train_rf_predictions))\n",
    "MAPE_train = 100 * np.mean(abs(train_rf_predictions - y_train)/abs(y_train))\n",
    "accuracy_train = 100 - MAPE_train\n",
    "r2_train = metrics.r2_score(y_train, train_rf_predictions)\n",
    "\n",
    "MAE_test = metrics.mean_absolute_error(y_test, rf_predictions)\n",
    "RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, rf_predictions))\n",
    "MAPE_test = 100 * np.mean(abs(rf_predictions - y_test)/abs(y_test))\n",
    "accuracy_test = 100 - MAPE_test\n",
    "r2_test = metrics.r2_score(y_test, rf_predictions)\n",
    "print(\"Evaluation for train:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Train:', MAE_train)    \n",
    "#print('Root Mean Squared Error Train:', RMSE_train)\n",
    "#print('Mean Absolute Percentage Error Train:', MAPE_train)\n",
    "print('Accuracy Train', str(accuracy_train) + \"%\")\n",
    "print('r2_score Train:',r2_train)\n",
    "print()\n",
    "print()\n",
    "print(\"Evaluation for test:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Test:', MAE_test)    \n",
    "#print('Root Mean Squared Error Test:', RMSE_test)\n",
    "#print('Mean Absolute Percentage Error Test:', MAPE_test)\n",
    "print('Accuracy Test', str(accuracy_test) + \"%\")\n",
    "print('r2_score Test:', r2_test)\n",
    "print(\"score\",lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind = np.argsort(np.abs(lr.coef_))[::-1][:24]\n",
    "#cols =x1.columns[ind]\n",
    "#vals = np.sort(np.abs(lr.coef_))[::-1][:24]\n",
    "#print(cols,vals)\n",
    "#pt = pd.Series(vals, index=cols).plot('barh', title = 'Important variables in Linear Regression')\n",
    "#pl.set_xlabel(\"Coefficient Strength\")\n",
    "#pl.set_ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for HTOX,HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain (2193, 2)\n",
      "XTest (940, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1=data[['HTOX','HC']]\n",
    "\n",
    "y = data['annual_count_avg']\n",
    "\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(x1, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = RSEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "X_train = scaler.transform(X_train1)\n",
    "X_test = scaler.transform(X_test1)\n",
    "\n",
    "print(\"XTrain\",X_train.shape)\n",
    "print(\"XTest\",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model \n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit on training data\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for train:\n",
      "\n",
      "Accuracy Train 0.3190437064941989%\n",
      "r2_score Train: 0.4714775218611794\n",
      "\n",
      "\n",
      "Evaluation for test:\n",
      "\n",
      "Accuracy Test -0.16613741029571827%\n",
      "r2_score Test: 0.11461408330990763\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "train_rf_predictions = lr.predict(X_train)\n",
    "rf_predictions = lr.predict(X_test)\n",
    "MAE_train = metrics.mean_absolute_error(y_train, train_rf_predictions)\n",
    "RMSE_train = np.sqrt(metrics.mean_squared_error(y_train, train_rf_predictions))\n",
    "MAPE_train = 100 * np.mean(abs(train_rf_predictions - y_train)/abs(y_train))\n",
    "accuracy_train = 100 - MAPE_train\n",
    "r2_train = metrics.r2_score(y_train, train_rf_predictions)\n",
    "\n",
    "MAE_test = metrics.mean_absolute_error(y_test, rf_predictions)\n",
    "RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, rf_predictions))\n",
    "MAPE_test = 100 * np.mean(abs(rf_predictions - y_test)/abs(y_test))\n",
    "accuracy_test = 100 - MAPE_test\n",
    "r2_test = metrics.r2_score(y_test, rf_predictions)\n",
    "print(\"Evaluation for train:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Train:', MAE_train)    \n",
    "#print('Root Mean Squared Error Train:', RMSE_train)\n",
    "#print('Mean Absolute Percentage Error Train:', MAPE_train)\n",
    "print('Accuracy Train', str(accuracy_train) + \"%\")\n",
    "print('r2_score Train:',r2_train)\n",
    "print()\n",
    "print()\n",
    "print(\"Evaluation for test:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Test:', MAE_test)    \n",
    "#print('Root Mean Squared Error Test:', RMSE_test)\n",
    "#print('Mean Absolute Percentage Error Test:', MAPE_test)\n",
    "print('Accuracy Test', str(accuracy_test) + \"%\")\n",
    "print('r2_score Test:', r2_test)\n",
    "print(\"score\",lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR for environmental factors in a county and cancer rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain (2193, 24)\n",
      "XTest (940, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1=data.loc[:, :'WATR']\n",
    "y = data['annual_count_avg']\n",
    "\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(x1, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = RSEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "X_train = scaler.transform(X_train1)\n",
    "X_test = scaler.transform(X_test1)\n",
    "\n",
    "print(\"XTrain\",X_train.shape)\n",
    "print(\"XTest\",X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=0, tol=1e-05, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "# Create the model \n",
    "\n",
    "svr = LinearSVR(random_state=0, tol=1e-5)\n",
    "# Fit on training data\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for train:\n",
      "\n",
      "Accuracy Train -inf%\n",
      "r2_score Train: 0.32574365212920087\n",
      "\n",
      "\n",
      "Evaluation for test:\n",
      "\n",
      "Accuracy Test -inf%\n",
      "r2_score Test: 0.1925047582004683\n",
      "score 0.1925047582004683\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "train_rf_predictions = svr.predict(X_train)\n",
    "rf_predictions = svr.predict(X_test)\n",
    "MAE_train = metrics.mean_absolute_error(y_train, train_rf_predictions)\n",
    "RMSE_train = np.sqrt(metrics.mean_squared_error(y_train, train_rf_predictions))\n",
    "MAPE_train = 100 * np.mean(abs(train_rf_predictions - y_train)/abs(y_train))\n",
    "accuracy_train = 100 - MAPE_train\n",
    "r2_train = metrics.r2_score(y_train, train_rf_predictions)\n",
    "\n",
    "MAE_test = metrics.mean_absolute_error(y_test, rf_predictions)\n",
    "RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, rf_predictions))\n",
    "MAPE_test = 100 * np.mean(abs(rf_predictions - y_test)/abs(y_test))\n",
    "accuracy_test = 100 - MAPE_test\n",
    "r2_test = metrics.r2_score(y_test, rf_predictions)\n",
    "print(\"Evaluation for train:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Train:', MAE_train)    \n",
    "#print('Root Mean Squared Error Train:', RMSE_train)\n",
    "#print('Mean Absolute Percentage Error Train:', MAPE_train)\n",
    "print('Accuracy Train', str(accuracy_train) + \"%\")\n",
    "print('r2_score Train:',r2_train)\n",
    "print()\n",
    "print()\n",
    "print(\"Evaluation for test:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Test:', MAE_test)    \n",
    "#print('Root Mean Squared Error Test:', RMSE_test)\n",
    "#print('Mean Absolute Percentage Error Test:', MAPE_test)\n",
    "print('Accuracy Test', str(accuracy_test) + \"%\")\n",
    "print('r2_score Test:', r2_test)\n",
    "print(\"score\",svr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR for HTOX,HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting for test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain (2193, 2)\n",
      "XTest (940, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1=data[['HTOX','HC']]\n",
    "\n",
    "y = data['annual_count_avg']\n",
    "\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(x1, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = RSEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "X_train = scaler.transform(X_train1)\n",
    "X_test = scaler.transform(X_test1)\n",
    "\n",
    "print(\"XTrain\",X_train.shape)\n",
    "print(\"XTest\",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=0, tol=1e-05, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "# Create the model \n",
    "\n",
    "svr = LinearSVR(random_state=0, tol=1e-5)\n",
    "# Fit on training data\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for train:\n",
      "\n",
      "Accuracy Train -inf%\n",
      "r2_score Train: -0.0294099288709071\n",
      "\n",
      "\n",
      "Evaluation for test:\n",
      "\n",
      "Accuracy Test -inf%\n",
      "r2_score Test: -0.08589664158110089\n",
      "score -0.08589664158110089\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "train_rf_predictions = svr.predict(X_train)\n",
    "rf_predictions = svr.predict(X_test)\n",
    "MAE_train = metrics.mean_absolute_error(y_train, train_rf_predictions)\n",
    "RMSE_train = np.sqrt(metrics.mean_squared_error(y_train, train_rf_predictions))\n",
    "MAPE_train = 100 * np.mean(abs(train_rf_predictions - y_train)/abs(y_train))\n",
    "accuracy_train = 100 - MAPE_train\n",
    "r2_train = metrics.r2_score(y_train, train_rf_predictions)\n",
    "\n",
    "MAE_test = metrics.mean_absolute_error(y_test, rf_predictions)\n",
    "RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, rf_predictions))\n",
    "MAPE_test = 100 * np.mean(abs(rf_predictions - y_test)/abs(y_test))\n",
    "accuracy_test = 100 - MAPE_test\n",
    "r2_test = metrics.r2_score(y_test, rf_predictions)\n",
    "print(\"Evaluation for train:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Train:', MAE_train)    \n",
    "#print('Root Mean Squared Error Train:', RMSE_train)\n",
    "#print('Mean Absolute Percentage Error Train:', MAPE_train)\n",
    "print('Accuracy Train', str(accuracy_train) + \"%\")\n",
    "print('r2_score Train:',r2_train)\n",
    "print()\n",
    "print()\n",
    "print(\"Evaluation for test:\")\n",
    "print()\n",
    "#print('Mean Absolute Error Test:', MAE_test)    \n",
    "#print('Root Mean Squared Error Test:', RMSE_test)\n",
    "#print('Mean Absolute Percentage Error Test:', MAPE_test)\n",
    "print('Accuracy Test', str(accuracy_test) + \"%\")\n",
    "print('r2_score Test:', r2_test)\n",
    "print(\"score\",svr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
